### 实战：基于GLM4的智能学习助教
**主要模块**
chrome客户端：实现向量化的数据库存入，查询
chrome服务器端
导入大模型向量化模块
大模型导入智能问答模块
主函数模块
gradio界面化模块

## 1.chroma服务器端客户端准备
- 已在后台启动chroma的服务器端，负责存储和检索向量数据。
- 客户端用于与chroma服务器进行交互，实现数据的写入和查询。
这部分写了def chroma_insert(embeddings, concents, keywords):实现数据存入

还有def chroma_query(query_embedding, collection, top_k=1):函数，实现数据查询



## 2.embedding模块准备
- 声明了`process(failname)`函数：用于数据预处理，输入参数为json文件名，输出为两个列表：
  - `keywords[]`：提取的干化词（关键词）列表。
  - `contents[]`：对应的资料内容列表。
- 声明了`api_embed(keywords)`函数：用于将`process(failname)`函数生成的`keywords[]`进行向量化，生成维度为768的embedding向量，支持批量处理（如长度为50的列表）。
- **补充说明：**
  - 将chroma客户端的创建操作移动到了主函数中，这样embedding模块和后续的问答模块问题向量化都可以直接复用同一个客户端实例，避免重复初始化，提升代码结构清晰度和资源利用效率。


## 3.大模型导入智能问答模块
首先通过def question_embedding(question):函数对问题实现向量化，    接受用户问题，返回向量，input: question - 用户输入的问题，output: q_emb - 问题的向量表示——这里接下来先写一下chroma模块的向量存入

## 4.gradio模块
这里目前有两个参数大模型的回答answer，用户的问题question,实现history，聊天记录的保存，还有回复用户问题
把gradio的界面封装了成了一个函数

## 5.主函数模块
工作流程
先调用
